
============================= M1 Pro =============================

---- Training a transformers language model ----
=> Values from three executions

Framework: pytorch
	Average: 1806.639595190684s - Median: 1818.6110489368439s

Framework: mlx
	Average: 1157.0066788196564s - Median: 1154.6633532047272s


---- Training BERT ----
=> Values from three executions

Framework: pytorch
	Average: 751.028749704361s - Median: 753.6784768104553s

Framework: mlx
	Average: 718.3554696242014s - Median: 718.211642742157s


---- Whisper inference ----
=> Values from ten executions

Framework: pytorch
	Average: 31.998124384880064s - Median: 31.96485936641693s

Framework: mlx
	Average: 8.509361457824706s - Median: 8.509169936180115s

---- TinyLLama inference ----
=> Values from ten executions

Framework: pytorch
	Average: 59.274635887146s - Median: 55.8025221824646s

Framework: mlx
	Average: 33.38054447174072s - Median: 33.322925329208374s

---- CPU/GPU switch ----
=> Values from ten executions

Framework: pytorch
	Average: 349.7299320459366s - Median: 349.9100536108017s

Framework: mlx
	Average: 270.1572776556015s - Median: 271.8326184749603s

==================================================================

============================= M1 Max =============================
====================== 64GB Unified Memory =======================
==================== 10 CPU and 32 GPU Cores =====================

---- Training a transformers language model ----
=> Values from three executions

Framework: pytorch
	Average: 

Framework: mlx
	Average: 


---- Training BERT ----
=> Values from three executions

Framework: pytorch
	Average: 

Framework: mlx
	Average: 


---- Whisper inference ----
=> Values from ten executions

Framework: pytorch 
(Had to "export PYTORCH_ENABLE_MPS_FALLBACK=1" due to an "op not implemented on MPS" error)
	Average: 21.43549997806549s - Median: 21.204530119895935s

Framework: mlx
	Average: 6.946336317062378s - Median: 6.937196493148804s


---- TinyLLama inference ----
=> Values from ten executions

Framework: pytorch
	Average: 50.98743650913239s - Median: 47.73779845237732s

Framework: mlx
	Average: 20.61291913986206s - Median: 20.613165140151978s


---- CPU/GPU switch ----
=> Values from ten executions

Framework: pytorch
	Average: 251.71098244190216s - Median: 252.021404504776s

Framework: mlx
	Average: Framework: mlx
	Average: 214.5735635280609s - Median: 214.57463908195496s

==================================================================

============================= M3 Max =============================

---- Training a transformers language model ----
=> Values from three executions

Framework: pytorch
	Average: 912.5205717086792s - Median: 924.3736660480499s

Framework: mlx
	Average: 426.00355768203735s - Median: 426.1944200992584s


---- Training BERT ----
=> Values from three executions

Framework: pytorch
	Average: 550.2911033630371s - Median: 544.6988077163696s

Framework: mlx
	Average: 408.45258100827533s - Median: 408.62774896621704s


---- Whisper inference ----
=> Values from ten executions

Framework: pytorch
	Average: 17.909158730506896s - Median: 17.877812027931213s

Framework: mlx
	Average: 4.8507798433303835s - Median: 4.839159846305847s

---- TinyLLama inference ----
=> Values from ten executions

Framework: pytorch
	Average: 36.182030129432675s - Median: 34.26037609577179s

Framework: mlx
	Average: 15.41469841003418s - Median: 15.389396786689758s

---- CPU/GPU switch ----
=> Values from ten executions

Framework: pytorch
	Average: 146.35703275203704s - Median: 146.41792500019073s

Framework: mlx
	Average: 140.5102721452713s - Median: 140.51127195358276s

==================================================================
